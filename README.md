# ğŸ¤– IA Server - Backend de Inteligencia Artificial para WhatsApp

API REST en Node.js/Express que funciona como backend de inteligencia artificial para un sistema de gestiÃ³n de listas de espera de restaurantes vÃ­a WhatsApp, usando Ollama + Llama 3.2.

## ğŸ“‹ Tabla de Contenidos

- [CaracterÃ­sticas](#caracterÃ­sticas)
- [Arquitectura](#arquitectura)
- [Requisitos Previos](#requisitos-previos)
- [InstalaciÃ³n](#instalaciÃ³n)
- [ConfiguraciÃ³n](#configuraciÃ³n)
- [API Endpoints](#api-endpoints)
- [IntegraciÃ³n con Next.js](#integraciÃ³n-con-nextjs)
- [Deployment](#deployment)
- [Testing](#testing)
- [Troubleshooting](#troubleshooting)

## âœ¨ CaracterÃ­sticas

- ğŸ¤– **Procesamiento de IA con Ollama**: Usa Llama 3.2 para respuestas naturales
- ğŸ­ **Sistema Multi-Agente**: MÃºltiples agentes especializados con diferentes propÃ³sitos ([Ver AGENTS.md](AGENTS.md))
- ğŸ’¬ **GestiÃ³n de Conversaciones**: Mantiene historial de Ãºltimos 10 mensajes por conversaciÃ³n
- ğŸ¯ **AnÃ¡lisis de Intenciones**: Clasifica mensajes en acciones especÃ­ficas automÃ¡ticamente
- âš¡ **Procesamiento por Lotes**: Endpoint batch para mÃºltiples mensajes
- ğŸ”’ **Seguridad**: AutenticaciÃ³n con API Key, CORS, Helmet, Rate Limiting
- ğŸ“Š **Cache Inteligente**: Redis para conversaciones y contexto
- ğŸ”„ **Retry Logic**: Reintentos automÃ¡ticos en fallos de Ollama
- ğŸ“ **Logging Estructurado**: Winston para logs detallados
- âœ… **ValidaciÃ³n Robusta**: Zod para validaciÃ³n de esquemas
- ğŸš€ **Process Management**: PM2 para producciÃ³n con cluster mode
- ğŸ”Œ **API Flexible**: Soporte para mÃºltiples agentes y casos de uso

## ğŸ—ï¸ Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      HTTP/REST      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Next.js   â”‚ â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ â”‚  IA Server   â”‚
â”‚  (WhatsApp) â”‚                     â”‚  (Express)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                           â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â†“                      â†“                      â†“
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  Ollama  â”‚          â”‚  Redis   â”‚          â”‚PostgreSQLâ”‚
              â”‚(Llama3.2)â”‚          â”‚ (Cache)  â”‚          â”‚(Opcional)â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flujo de Procesamiento

1. **Cliente WhatsApp** envÃ­a mensaje â†’ **Next.js**
2. **Next.js** envÃ­a a `/api/chat` con contexto del negocio
3. **IA Server** recupera historial de Redis
4. **Ollama** procesa con Llama 3.2 y genera respuesta
5. Parsea **acciones** estructuradas de la respuesta
6. Guarda en **historial** y retorna a Next.js
7. **Next.js** ejecuta acciones y envÃ­a respuesta por WhatsApp

## ğŸ“¦ Requisitos Previos

- **Node.js** 22+ y npm 10+
- **Redis** 6+ (para cache de conversaciones)
- **Ollama** con modelo Llama 3.2
- **PM2** (opcional, para producciÃ³n)

### InstalaciÃ³n de Dependencias

#### Linux (Ubuntu/Debian)

```bash
# Node.js 22
curl -fsSL https://deb.nodesource.com/setup_22.x | sudo -E bash -
sudo apt-get install -y nodejs

# Redis
sudo apt-get install redis-server
sudo systemctl enable redis-server
sudo systemctl start redis-server

# Ollama
curl -fsSL https://ollama.ai/install.sh | sh
ollama pull llama3.2

# PM2 (opcional)
sudo npm install -g pm2
```

#### macOS

```bash
# Homebrew
brew install node redis ollama

# Iniciar servicios
brew services start redis
ollama serve &

# Descargar modelo
ollama pull llama3.2

# PM2
npm install -g pm2
```

## ğŸš€ InstalaciÃ³n

### 1. Clonar/Descargar el proyecto

```bash
cd /tmp/ia-server
```

### 2. Ejecutar script de setup

```bash
chmod +x setup.sh
./setup.sh
```

El script verificarÃ¡:
- âœ… Node.js 22+
- âœ… Redis instalado y corriendo
- âœ… Ollama instalado con modelo llama3.2
- âœ… InstalaciÃ³n de dependencias npm
- âœ… CreaciÃ³n de `.env`
- âœ… Build de TypeScript

### 3. Configurar variables de entorno

```bash
nano .env
```

Edita las siguientes variables:

```env
# Server
PORT=4000

# Modo de ejecuciÃ³n: production, development, test
# - production: responde a todos los chats de clientes, ignora mensajes propios (fromMe)
# - test: responde SOLO en tu chat personal de WhatsApp, ignora otros chats
#   Ãºtil para probar sin enviar respuestas a clientes reales
NODE_ENV=production

# Ollama
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2
OLLAMA_TIMEOUT=30000

# Security - Â¡CAMBIAR EN PRODUCCIÃ“N!
API_KEY=tu_api_key_secreta_aqui_cambiar_en_produccion
ALLOWED_ORIGINS=https://tu-dominio.com,http://localhost:3000

# Redis
REDIS_URL=redis://localhost:6379

# Logging
LOG_LEVEL=info
```

## âš™ï¸ ConfiguraciÃ³n

### Generar API Key Segura

```bash
# Generar una API key aleatoria
node -e "console.log(require('crypto').randomBytes(32).toString('hex'))"
```

Copia el resultado a `API_KEY` en `.env`.

### Configurar CORS

Agrega los dominios permitidos en `ALLOWED_ORIGINS`:

```env
ALLOWED_ORIGINS=https://mi-app.com,https://admin.mi-app.com,http://localhost:3000
```

## ğŸ“¡ API Endpoints

### 1. POST `/api/chat`

Procesa un mensaje con IA usando historial de conversaciÃ³n.

**Headers:**
```
Authorization: Bearer YOUR_API_KEY
Content-Type: application/json
```

**Body:**
```json
{
  "phone": "+5491112345678",
  "message": "Hola, quiero anotarme para 4 personas",
  "businessId": "123e4567-e89b-12d3-a456-426614174000",
  "context": {
    "businessName": "Restaurante La Plaza",
    "businessAddress": "Av. Corrientes 1234, CABA",
    "businessHours": "12:00 - 23:00",
    "currentWaitlist": 5,
    "averageWaitTime": 20,
    "customerInfo": {
      "isKnown": false
    }
  }
}
```

**Response:**
```json
{
  "response": "Â¡Hola! Claro, te anoto para 4 personas. Â¿Me podrÃ­as decir tu nombre completo? El tiempo de espera estimado es de 20 minutos.",
  "actions": [
    {
      "type": "REGISTER",
      "data": {
        "partySize": 4,
        "status": "pending_name"
      },
      "confidence": 0.9
    }
  ],
  "confidence": 0.92
}
```

### 2. POST `/api/analyze-intent`

Determina la intenciÃ³n de un mensaje.

**Body:**
```json
{
  "message": "Quiero cancelar mi reserva",
  "context": {
    "businessName": "Restaurante La Plaza"
  }
}
```

**Response:**
```json
{
  "intent": "cancel",
  "entities": {
    "action": "cancel"
  },
  "confidence": 0.95
}
```

### 3. DELETE `/api/conversations/:phone`

Limpia el historial de conversaciÃ³n de un telÃ©fono.

**Example:**
```bash
curl -X DELETE \
  -H "Authorization: Bearer YOUR_API_KEY" \
  http://localhost:4000/api/conversations/+5491112345678
```

**Response:** `204 No Content`

### 4. GET `/health`

Health check del servidor (sin autenticaciÃ³n).

**Response:**
```json
{
  "status": "healthy",
  "ollama": true,
  "redis": true,
  "model": "llama3.2",
  "uptime": 3600,
  "timestamp": "2026-02-06T10:30:00Z"
}
```

### 5. POST `/api/batch`

Procesa mÃºltiples mensajes en batch (mÃ¡x. 50).

**Body:**
```json
{
  "messages": [
    {
      "phone": "+5491112345678",
      "message": "Hola",
      "businessId": "uuid-1",
      "context": { "businessName": "Restaurant 1" }
    },
    {
      "phone": "+5491187654321",
      "message": "Quiero reservar",
      "businessId": "uuid-2",
      "context": { "businessName": "Restaurant 2" }
    }
  ]
}
```

**Response:**
```json
{
  "results": [
    {
      "index": 0,
      "success": true,
      "data": {
        "response": "...",
        "actions": [],
        "confidence": 0.85
      }
    },
    {
      "index": 1,
      "success": true,
      "data": {
        "response": "...",
        "actions": [],
        "confidence": 0.9
      }
    }
  ],
  "processedCount": 2,
  "failedCount": 0
}
```

---

## ğŸ­ Sistema Multi-Agente (Nuevo)

El servidor ahora soporta mÃºltiples agentes especializados. **Ver [AGENTS.md](AGENTS.md) para documentaciÃ³n completa**.

### 6. GET `/api/agents`

Lista todos los agentes disponibles.

**Example:**
```bash
curl -H "Authorization: Bearer YOUR_API_KEY" \
  http://localhost:4000/api/agents
```

### 7. GET `/api/agents/:agentId`

Obtiene detalles de un agente especÃ­fico.

**Example:**
```bash
curl -H "Authorization: Bearer YOUR_API_KEY" \
  http://localhost:4000/api/agents/waitlist
```

### 8. POST `/api/agents/:agentId/chat`

Genera una respuesta usando un agente especÃ­fico.

**Example:**
```bash
curl -X POST \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Hola, cuÃ¡l es mi posiciÃ³n?",
    "conversationId": "user-123",
    "context": {"phone": "+1234567890"}
  }' \
  http://localhost:4000/api/agents/waitlist/chat
```

**Response:**
```json
{
  "success": true,
  "data": {
    "response": "Hola! Con gusto te ayudo...",
    "action": "CHECK_STATUS",
    "conversationId": "user-123",
    "agent": {
      "id": "waitlist",
      "name": "Asistente de Lista de Espera"
    },
    "processingTime": 1245
  }
}
```

### 9. DELETE `/api/agents/:agentId/conversations/:conversationId`

Limpia el historial de una conversaciÃ³n especÃ­fica.

---

## ğŸ”Œ IntegraciÃ³n con Next.js

### Ejemplo de Cliente

```typescript
// lib/ia-client.ts
const IA_API_URL = process.env.IA_SERVER_URL || 'http://localhost:4000';
const IA_API_KEY = process.env.IA_API_KEY;

export async function processMessage(
  phone: string,
  message: string,
  businessId: string,
  context?: any
) {
  const response = await fetch(`${IA_API_URL}/api/chat`, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${IA_API_KEY}`,
    },
    body: JSON.stringify({
      phone,
      message,
      businessId,
      context,
    }),
  });

  if (!response.ok) {
    throw new Error(`IA Server error: ${response.status}`);
  }

  return await response.json();
}
```

### Uso en API Route

```typescript
// app/api/whatsapp/route.ts
import { processMessage } from '@/lib/ia-client';

export async function POST(req: Request) {
  const { phone, message, businessId } = await req.json();

  // Obtener contexto del negocio de tu DB
  const business = await db.business.findUnique({ where: { id: businessId } });
  const waitlist = await db.waitlist.count({ where: { businessId } });

  // Procesar con IA
  const aiResponse = await processMessage(phone, message, businessId, {
    businessName: business.name,
    businessAddress: business.address,
    currentWaitlist: waitlist,
    averageWaitTime: 15,
  });

  // Ejecutar acciones
  for (const action of aiResponse.actions) {
    if (action.type === 'REGISTER') {
      // Crear entrada en waitlist
      await db.waitlist.create({
        data: {
          businessId,
          phone,
          partySize: action.data.partySize,
        },
      });
    }
    // ... otras acciones
  }

  // Enviar respuesta por WhatsApp con Baileys
  await sendWhatsAppMessage(phone, aiResponse.response);

  return Response.json({ success: true });
}
```

## ğŸš€ Deployment

### Modo Desarrollo

```bash
npm run dev
```

### Modo ProducciÃ³n (Node)

```bash
npm run build
npm start
```

### Modo ProducciÃ³n (PM2)

```bash
# Iniciar
npm run pm2:start

# Ver logs
pm2 logs ia-server

# Monitorear
pm2 monit

# Reiniciar
npm run pm2:restart

# Detener
npm run pm2:stop
```

### Script de Deployment

```bash
chmod +x deploy.sh
./deploy.sh
```

### Systemd Service (Linux)

Crear `/etc/systemd/system/ia-server.service`:

```ini
[Unit]
Description=IA Server
After=network.target redis.service

[Service]
Type=simple
User=your-user
WorkingDirectory=/path/to/ia-server
Environment=NODE_ENV=production
ExecStart=/usr/bin/npm start
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
```

```bash
sudo systemctl enable ia-server
sudo systemctl start ia-server
sudo systemctl status ia-server
```

## ğŸ§ª Testing

### Ejecutar Tests

```bash
# Todos los tests
npm test

# Watch mode
npm run test:watch

# Con cobertura
npm run test:coverage
```

### Tests Incluidos

- âœ… **Utils**: Actions parsing, prompts, entities extraction
- âœ… **Services**: Ollama service con mocks, retry logic
- âœ… **Integration**: API endpoints con supertest

### Probar Endpoints Manualmente

```bash
# Health check
curl http://localhost:4000/health

# Chat (requiere API key)
curl -X POST http://localhost:4000/api/chat \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -d '{
    "phone": "+5491112345678",
    "message": "Hola, quiero anotarme",
    "businessId": "123e4567-e89b-12d3-a456-426614174000",
    "context": {
      "businessName": "Mi Restaurante",
      "currentWaitlist": 3,
      "averageWaitTime": 15
    }
  }'

# Analyze intent
curl -X POST http://localhost:4000/api/analyze-intent \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -d '{
    "message": "Quiero cancelar"
  }'

# Clear conversation
curl -X DELETE http://localhost:4000/api/conversations/+5491112345678 \
  -H "Authorization: Bearer YOUR_API_KEY"
```

### Probar con WhatsApp en Modo Test

Para probar la IA sin enviar respuestas a clientes reales:

1. **Configurar modo test**:
   ```bash
   # En .env
   NODE_ENV=test
   ```

2. **Iniciar el servidor**:
   ```bash
   npm start
   ```

3. **Conectar WhatsApp** (escanear QR desde tu cuenta)

4. **Enviar mensajes desde tu propio chat de WhatsApp**:
   - âœ… El bot responderÃ¡ SOLO en tu chat personal
   - âŒ IgnorarÃ¡ mensajes de otros chats
   - âŒ No responderÃ¡ a clientes reales

5. **Volver a producciÃ³n**:
   ```bash
   # En .env
   NODE_ENV=production
   ```

> **Nota**: En modo `production`, el bot responde a todos los chats de clientes pero ignora tus propios mensajes (fromMe=true).

## ğŸ”§ Troubleshooting

### Ollama no responde

```bash
# Verificar si Ollama estÃ¡ corriendo
curl http://localhost:11434/api/tags

# Iniciar Ollama
ollama serve

# Verificar modelo descargado
ollama list

# Descargar modelo si falta
ollama pull llama3.2
```

### Redis no conecta

```bash
# Verificar si Redis estÃ¡ corriendo
redis-cli ping

# Iniciar Redis
# Linux
sudo systemctl start redis-server

# macOS
brew services start redis

# Verificar conexiÃ³n
redis-cli
> KEYS *
> QUIT
```

### Error: API_KEY not set

```bash
# Asegurarse que .env existe y tiene API_KEY
cat .env | grep API_KEY

# Si no existe, copiar de ejemplo
cp .env.example .env
nano .env
```

### Rate Limit Exceeded

El servidor tiene rate limiting de 100 req/min por IP. Para testing local:

```typescript
// Comentar temporalmente en src/index.ts
// app.use('/api', generalRateLimiter);
```

### Memory Issues

Si el servidor consume mucha memoria:

```bash
# Ajustar max memory en ecosystem.config.js
max_memory_restart: '500M'

# O reducir nÃºmero de instancias
instances: 1
```

### Ver Logs

```bash
# PM2 logs
pm2 logs ia-server

# Archivos de logs
tail -f logs/combined.log
tail -f logs/error.log
```

## ğŸ“Š Monitoreo

### PM2 Monitoring

```bash
pm2 monit
```

### Stats Endpoint

```bash
curl -H "Authorization: Bearer YOUR_API_KEY" \
  http://localhost:4000/stats
```

### Redis Keys

```bash
redis-cli
> KEYS conversation:*
> GET conversation:+5491112345678
> KEYS business:*
```

## ğŸ“ Estructura del Proyecto

```
ia-server/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ index.ts                 # Entry point
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ ollama.ts           # Ollama client config
â”‚   â”‚   â””â”€â”€ redis.ts            # Redis client config
â”‚   â”œâ”€â”€ controllers/
â”‚   â”‚   â”œâ”€â”€ chat.controller.ts   # Chat & batch handlers
â”‚   â”‚   â””â”€â”€ health.controller.ts # Health check
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ ollama.service.ts    # Ollama API wrapper
â”‚   â”‚   â”œâ”€â”€ conversation.service.ts # Conversation history
â”‚   â”‚   â”œâ”€â”€ intent.service.ts    # Intent analysis
â”‚   â”‚   â””â”€â”€ cache.service.ts     # Business context cache
â”‚   â”œâ”€â”€ middleware/
â”‚   â”‚   â”œâ”€â”€ auth.middleware.ts   # API key auth
â”‚   â”‚   â”œâ”€â”€ rateLimit.middleware.ts # Rate limiting
â”‚   â”‚   â””â”€â”€ validation.middleware.ts # Zod schemas
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ prompts.ts          # System prompts
â”‚   â”‚   â”œâ”€â”€ logger.ts           # Winston logger
â”‚   â”‚   â””â”€â”€ actions.ts          # Action parsing
â”‚   â”œâ”€â”€ types/
â”‚   â”‚   â””â”€â”€ index.ts            # TypeScript types
â”‚   â””â”€â”€ __tests__/              # Jest tests
â”œâ”€â”€ logs/                        # Log files
â”œâ”€â”€ dist/                        # Compiled JS
â”œâ”€â”€ .env                         # Environment variables
â”œâ”€â”€ ecosystem.config.js          # PM2 config
â”œâ”€â”€ setup.sh                     # Setup script
â”œâ”€â”€ deploy.sh                    # Deployment script
â””â”€â”€ README.md                    # Este archivo
```

## ğŸ“š DocumentaciÃ³n Adicional

- **[AGENTS.md](AGENTS.md)** - Sistema Multi-Agente: configuraciÃ³n, uso y creaciÃ³n de agentes personalizados
- **[TYPES_GENERATION.md](TYPES_GENERATION.md)** - GeneraciÃ³n de tipos de TypeScript desde Supabase (2 mÃ©todos)
- **[QUICK_START.md](QUICK_START.md)** - GuÃ­a rÃ¡pida de inicio
- **[ENDPOINTS.md](ENDPOINTS.md)** - DocumentaciÃ³n completa de API endpoints

## ğŸ¤ Contribuciones

Este es un proyecto interno. Para cambios:

1. Crear branch: `git checkout -b feature/nueva-funcionalidad`
2. Hacer cambios y tests
3. Commit: `git commit -m "DescripciÃ³n"`
4. Push: `git push origin feature/nueva-funcionalidad`

## ğŸ“„ Licencia

MIT

---

**Desarrollado para sistema de gestiÃ³n de listas de espera vÃ­a WhatsApp**
